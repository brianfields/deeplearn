{
  "id": "9435f1bf-472d-47c5-a759-99beadd98077",
  "title": "Gradient Descent Mastery",
  "description": "A focused look at optimization fundamentals for machine learning practitioners.",
  "learner_level": "intermediate",
  "learning_objectives": [
    {
      "id": "grad_unit_lo_1",
      "title": "Explain Gradient Updates",
      "description": "Explain how gradient descent updates parameters",
      "bloom_level": "Understand"
    },
    {
      "id": "grad_unit_lo_2",
      "title": "Compare Descent Strategies",
      "description": "Compare batch, stochastic, and mini-batch strategies",
      "bloom_level": "Analyze"
    }
  ],
  "target_lesson_count": 2,
  "source_material": "Lecture notes on convex optimization, annotated Python notebooks, and practical training logs.",
  "generated_from_topic": true,
  "is_global": false,
  "owner_key": "brian",
  "art_image_description": "Weimar Edge illustration of Gradient Descent Mastery highlighting Explain Gradient Updates, Compare Descent Strategies with petrol blue geometry and gilt accents.",
  "podcast_transcript": "Welcome to Gradient Descent Mastery. This intro podcast previews the lessons and invites learners into the unit's narrative arc.",
  "podcast_voice": "Plain",
  "lessons": [
    {
      "id": "94e348bf-0a0e-4bd6-8d71-1112ced6326e",
      "title": "Gradient Descent Fundamentals",
      "learner_level": "intermediate",
      "source_material": "Walk-through of loss landscape intuition with quadratic examples and contour diagrams.",
      "objectives": [
        {
          "id": "grad_unit_lo_1",
          "title": "Explain Gradient Updates",
          "description": "Explain how gradient descent updates parameters",
          "bloom_level": "Understand"
        },
        {
          "id": "grad_unit_lo_1",
          "title": "Explain Gradient Updates",
          "description": "Explain how gradient descent updates parameters",
          "bloom_level": "Understand"
        }
      ],
      "mcqs": [
        {
          "stem": "What happens when the learning rate is set too high?",
          "options": [
            {
              "text": "Updates overshoot and may diverge",
              "rationale_wrong": null
            },
            {
              "text": "Optimization halts immediately",
              "rationale_wrong": "Stopping occurs only if gradients become zero or errors occur."
            },
            {
              "text": "Gradients become zero regardless of the loss",
              "rationale_wrong": "Gradients depend on the loss surface, not the learning rate."
            }
          ],
          "correct_index": 0,
          "cognitive_level": "Analyze",
          "difficulty": "Medium",
          "misconceptions": [
            "higher_rate_faster"
          ],
          "correct_rationale": "Large steps can bounce across the valley and fail to converge."
        },
        {
          "stem": "Which equation represents one gradient descent step?",
          "options": [
            {
              "text": "\u03b8 := \u03b8 - \u03b1 \u2207J(\u03b8)",
              "rationale_wrong": null
            },
            {
              "text": "\u03b8 := \u03b8 + \u03b1 \u03b8",
              "rationale_wrong": "This ignores the gradient information entirely."
            },
            {
              "text": "\u03b8 := \u03b8 / \u03b1",
              "rationale_wrong": "Dividing by the learning rate is unrelated to descent."
            }
          ],
          "correct_index": 0,
          "cognitive_level": "Remember",
          "difficulty": "Easy",
          "misconceptions": [
            "missing_gradient"
          ],
          "correct_rationale": "The gradient guides the step direction while \u03b1 scales it."
        },
        {
          "stem": "Which quantity determines the direction of the update?",
          "options": [
            {
              "text": "The gradient of the loss",
              "rationale_wrong": null
            },
            {
              "text": "The learning rate alone",
              "rationale_wrong": "Learning rate only scales the update; it does not pick the direction."
            },
            {
              "text": "The batch size",
              "rationale_wrong": "Batch size influences noise, not direction."
            }
          ],
          "correct_index": 0,
          "cognitive_level": "Understand",
          "difficulty": "Medium",
          "misconceptions": [
            "direction_from_rate"
          ],
          "correct_rationale": "The gradient vector points toward steepest ascent, so we step opposite it."
        },
        {
          "stem": "When does vanilla gradient descent typically stop iterating?",
          "options": [
            {
              "text": "When the gradient norm falls near zero",
              "rationale_wrong": null
            },
            {
              "text": "After a single update",
              "rationale_wrong": "Multiple updates are required to reach an optimum."
            },
            {
              "text": "Once the loss increases once",
              "rationale_wrong": "A temporary increase can occur without ending training."
            }
          ],
          "correct_index": 0,
          "cognitive_level": "Analyze",
          "difficulty": "Medium",
          "misconceptions": [
            "stop_on_first_increase"
          ],
          "correct_rationale": "Convergence is reached when gradients vanish or a tolerance threshold is met."
        },
        {
          "stem": "Which hyperparameter scales how far each step travels?",
          "options": [
            {
              "text": "Learning rate",
              "rationale_wrong": null
            },
            {
              "text": "Momentum",
              "rationale_wrong": "Momentum adds history but does not alone scale basic step size."
            },
            {
              "text": "Epoch count",
              "rationale_wrong": "Epochs count passes through data, not step length."
            }
          ],
          "correct_index": 0,
          "cognitive_level": "Remember",
          "difficulty": "Easy",
          "misconceptions": [
            "epoch_controls_step"
          ],
          "correct_rationale": "The learning rate multiplies the gradient to set step magnitude."
        }
      ],
      "misconceptions": [],
      "confusables": [],
      "short_answers": [
        {
          "stem": "Which vector do we move opposite to descend the loss?",
          "canonical_answer": "negative gradient",
          "acceptable_answers": [
            "-gradient"
          ],
          "wrong_answers": [
            {
              "answer": "learning rate",
              "explanation": "The learning rate only scales the update; it is not the direction.",
              "misconception_ids": [
                "direction_from_rate"
              ]
            },
            {
              "answer": "loss surface",
              "explanation": "The surface defines the landscape but not the direction of travel.",
              "misconception_ids": []
            }
          ],
          "explanation_correct": "Gradient descent steps against the gradient vector to decrease the loss.",
          "learning_objectives_covered": [
            "grad_unit_lo_1"
          ],
          "cognitive_level": "Apply"
        },
        {
          "stem": "What term describes the function we minimize during training?",
          "canonical_answer": "loss function",
          "acceptable_answers": [
            "cost function",
            "objective"
          ],
          "wrong_answers": [
            {
              "answer": "activation",
              "explanation": "Activations are neuron outputs, not the optimization target.",
              "misconception_ids": []
            },
            {
              "answer": "dataset",
              "explanation": "The dataset is the input, while the loss function measures error.",
              "misconception_ids": []
            }
          ],
          "explanation_correct": "Training minimizes a loss function that measures prediction error.",
          "learning_objectives_covered": [
            "grad_unit_lo_1"
          ],
          "cognitive_level": "Remember"
        },
        {
          "stem": "Which hyperparameter controls the step size per update?",
          "canonical_answer": "learning rate",
          "acceptable_answers": [
            "step size"
          ],
          "wrong_answers": [
            {
              "answer": "batch size",
              "explanation": "Batch size affects noise, not the scaling of each gradient step.",
              "misconception_ids": [
                "bigger_always_better"
              ]
            },
            {
              "answer": "momentum",
              "explanation": "Momentum accumulates velocity but does not replace the rate itself.",
              "misconception_ids": []
            }
          ],
          "explanation_correct": "The learning rate multiplies the gradient to set how far we move.",
          "learning_objectives_covered": [
            "grad_unit_lo_1"
          ],
          "cognitive_level": "Understand"
        },
        {
          "stem": "What do we call a point where the gradient becomes zero?",
          "canonical_answer": "stationary point",
          "acceptable_answers": [
            "critical point"
          ],
          "wrong_answers": [
            {
              "answer": "global maximum",
              "explanation": "A zero gradient could be minimum, maximum, or saddle point.",
              "misconception_ids": []
            },
            {
              "answer": "divergence",
              "explanation": "Divergence means the algorithm blew up, not that gradients vanished.",
              "misconception_ids": []
            }
          ],
          "explanation_correct": "Stationary points have zero gradient and mark potential optima.",
          "learning_objectives_covered": [
            "grad_unit_lo_1"
          ],
          "cognitive_level": "Analyze"
        },
        {
          "stem": "Which variant uses the entire dataset for each update?",
          "canonical_answer": "batch gradient descent",
          "acceptable_answers": [
            "full batch"
          ],
          "wrong_answers": [
            {
              "answer": "stochastic descent",
              "explanation": "Stochastic descent uses one example per update.",
              "misconception_ids": []
            },
            {
              "answer": "mini-batch",
              "explanation": "Mini-batch uses subsets, not the complete dataset.",
              "misconception_ids": [
                "mini_batch_is_exact"
              ]
            }
          ],
          "explanation_correct": "Batch gradient descent computes gradients over all examples before stepping.",
          "learning_objectives_covered": [
            "grad_unit_lo_1"
          ],
          "cognitive_level": "Understand"
        }
      ],
      "podcast_transcript": "Gradient descent walks downhill on a loss landscape by following the negative gradient. Choosing the learning rate balances progress with stability. Too small and updates crawl; too large and the algorithm overshoots the valley. Visualizing contour plots helps practitioners tune the step size and anticipate oscillations."
    },
    {
      "id": "c91e9256-26f8-45aa-8390-3f80a903824f",
      "title": "Mini-Batch Strategies",
      "learner_level": "intermediate",
      "source_material": "Case study comparing batch, stochastic, and mini-batch training on image classifiers.",
      "objectives": [
        {
          "id": "grad_unit_lo_2",
          "title": "Compare Descent Strategies",
          "description": "Compare batch, stochastic, and mini-batch strategies",
          "bloom_level": "Analyze"
        },
        {
          "id": "grad_unit_lo_2",
          "title": "Compare Descent Strategies",
          "description": "Compare batch, stochastic, and mini-batch strategies",
          "bloom_level": "Analyze"
        }
      ],
      "mcqs": [
        {
          "stem": "Why choose mini-batch gradient descent over pure stochastic descent?",
          "options": [
            {
              "text": "It smooths gradient noise while remaining efficient",
              "rationale_wrong": null
            },
            {
              "text": "It eliminates the need for a learning rate",
              "rationale_wrong": "Learning rate tuning is still required."
            },
            {
              "text": "It guarantees convergence in one epoch",
              "rationale_wrong": "Convergence still depends on many factors."
            }
          ],
          "correct_index": 0,
          "cognitive_level": "Analyze",
          "difficulty": "Medium",
          "misconceptions": [
            "mini_batch_is_exact"
          ],
          "correct_rationale": "Mini-batches reduce variance while keeping computation tractable."
        },
        {
          "stem": "Which batch size balances speed and noise for many image tasks?",
          "options": [
            {
              "text": "A power of two such as 64",
              "rationale_wrong": null
            },
            {
              "text": "Batch size of 1 to avoid memory use",
              "rationale_wrong": "Size 1 is pure stochastic descent."
            },
            {
              "text": "Full dataset size each step",
              "rationale_wrong": "Full batches maximize stability but reduce responsiveness."
            }
          ],
          "correct_index": 0,
          "cognitive_level": "Apply",
          "difficulty": "Easy",
          "misconceptions": [
            "bigger_always_better"
          ],
          "correct_rationale": "Powers of two align with hardware and offer a practical trade-off."
        },
        {
          "stem": "How does decreasing batch size affect gradient estimates?",
          "options": [
            {
              "text": "Noise increases, enabling exploratory moves",
              "rationale_wrong": null
            },
            {
              "text": "Noise decreases to zero",
              "rationale_wrong": "Noise only vanishes with full-batch updates."
            },
            {
              "text": "Gradients become biased upward",
              "rationale_wrong": "Mini-batch gradients remain unbiased on average."
            }
          ],
          "correct_index": 0,
          "cognitive_level": "Understand",
          "difficulty": "Medium",
          "misconceptions": [
            "variance_equals_bias"
          ],
          "correct_rationale": "Smaller batches sample fewer examples so variance grows, which can help escape shallow minima."
        },
        {
          "stem": "Which tool accelerates mini-batch training on GPUs?",
          "options": [
            {
              "text": "Vectorized tensor operations",
              "rationale_wrong": null
            },
            {
              "text": "Serial parameter updates",
              "rationale_wrong": "Serial updates negate parallel benefits."
            },
            {
              "text": "Manual gradient calculation",
              "rationale_wrong": "Automatic differentiation handles gradients efficiently."
            }
          ],
          "correct_index": 0,
          "cognitive_level": "Apply",
          "difficulty": "Medium",
          "misconceptions": [
            "gpu_needs_serial"
          ],
          "correct_rationale": "Leveraging tensor libraries keeps mini-batch operations parallel and fast."
        },
        {
          "stem": "What schedule often follows a plateau in validation loss?",
          "options": [
            {
              "text": "Reduce the learning rate",
              "rationale_wrong": null
            },
            {
              "text": "Increase batch size immediately",
              "rationale_wrong": "Larger batches may hide useful noise instead of improving convergence."
            },
            {
              "text": "Restart training from scratch",
              "rationale_wrong": "Restarts waste progress unless using cyclic schedules."
            }
          ],
          "correct_index": 0,
          "cognitive_level": "Analyze",
          "difficulty": "Medium",
          "misconceptions": [
            "always_increase_batch"
          ],
          "correct_rationale": "Reducing the learning rate after a plateau helps mini-batch updates settle into minima."
        }
      ],
      "misconceptions": [],
      "confusables": [],
      "short_answers": [
        {
          "stem": "What noise-reducing technique averages gradients across replicas?",
          "canonical_answer": "gradient accumulation",
          "acceptable_answers": [
            "gradient averaging"
          ],
          "wrong_answers": [
            {
              "answer": "dropout",
              "explanation": "Dropout regularizes activations but does not average gradients.",
              "misconception_ids": []
            },
            {
              "answer": "weight decay",
              "explanation": "Weight decay adds a penalty term instead of averaging gradients.",
              "misconception_ids": []
            }
          ],
          "explanation_correct": "Accumulating gradients over micro-batches keeps updates stable when memory is limited.",
          "learning_objectives_covered": [
            "grad_unit_lo_2"
          ],
          "cognitive_level": "Apply"
        },
        {
          "stem": "Which schedule gradually lowers the learning rate during training?",
          "canonical_answer": "learning rate decay",
          "acceptable_answers": [
            "lr decay",
            "annealing"
          ],
          "wrong_answers": [
            {
              "answer": "batch norm",
              "explanation": "Batch normalization rescales activations, not the learning rate.",
              "misconception_ids": []
            },
            {
              "answer": "weight initialization",
              "explanation": "Initialization occurs before training and is not a schedule.",
              "misconception_ids": []
            }
          ],
          "explanation_correct": "Learning rate decay reduces step sizes so mini-batches converge smoothly.",
          "learning_objectives_covered": [
            "grad_unit_lo_2"
          ],
          "cognitive_level": "Understand"
        },
        {
          "stem": "What metric do practitioners watch to detect overfitting?",
          "canonical_answer": "validation loss",
          "acceptable_answers": [
            "val loss",
            "validation error"
          ],
          "wrong_answers": [
            {
              "answer": "training accuracy",
              "explanation": "Training accuracy rises even when generalization suffers.",
              "misconception_ids": []
            },
            {
              "answer": "gradient norm",
              "explanation": "Gradient norms show optimization progress, not overfitting directly.",
              "misconception_ids": []
            }
          ],
          "explanation_correct": "Validation loss reveals whether mini-batch updates still improve generalization.",
          "learning_objectives_covered": [
            "grad_unit_lo_2"
          ],
          "cognitive_level": "Analyze"
        },
        {
          "stem": "Which optimizer adds momentum to damp oscillations?",
          "canonical_answer": "momentum",
          "acceptable_answers": [
            "sgd with momentum"
          ],
          "wrong_answers": [
            {
              "answer": "adam",
              "explanation": "Adam adapts per-parameter rates beyond simple momentum.",
              "misconception_ids": []
            },
            {
              "answer": "dropout",
              "explanation": "Dropout randomly masks activations; it is not an optimizer.",
              "misconception_ids": []
            }
          ],
          "explanation_correct": "Momentum smooths noisy mini-batch gradients by accumulating velocity.",
          "learning_objectives_covered": [
            "grad_unit_lo_2"
          ],
          "cognitive_level": "Apply"
        },
        {
          "stem": "How do we describe running several batches in parallel on multiple GPUs?",
          "canonical_answer": "data parallelism",
          "acceptable_answers": [
            "data parallel"
          ],
          "wrong_answers": [
            {
              "answer": "model parallelism",
              "explanation": "Model parallelism splits layers across devices instead of batches.",
              "misconception_ids": []
            },
            {
              "answer": "quantization",
              "explanation": "Quantization compresses weights rather than distributing batches.",
              "misconception_ids": []
            }
          ],
          "explanation_correct": "Data parallelism copies the model on each device and splits mini-batches for speed.",
          "learning_objectives_covered": [
            "grad_unit_lo_2"
          ],
          "cognitive_level": "Understand"
        }
      ],
      "podcast_transcript": "Mini-batches blend the stability of batch training with the responsiveness of stochastic updates. Smaller batches introduce gradient noise that can escape shallow minima, while larger batches leverage hardware parallelism. Practitioners often start with powers of two (32, 64, 128) and adjust based on validation loss curves."
    }
  ],
  "resources": [
    {
      "id": "bc9ea4cb-ac1d-4712-aeb3-a6a880cc9f38",
      "user_id": 1,
      "resource_type": "file_upload",
      "filename": "gradient-descent-cheatsheet.md",
      "extracted_text": "Gradient descent tuning cheatsheet\n\u2022 Start with learning rate 0.1 for convex demos, decay by 0.5 when oscillations persist.\n\u2022 Clip gradients above 5.0 to stabilize mini-batch updates.\n\u2022 Log validation loss every 10 steps; trigger warm restart if plateau > 30 steps.",
      "extraction_metadata": {},
      "file_size": 271,
      "object_store_document_id": "51a7e0ce-b53a-4bca-8f24-2e03b8153b35",
      "created_at": "2025-10-30 00:23:07.850994+00:00",
      "updated_at": "2025-10-30 00:23:07.850994+00:00",
      "document": {
        "id": "51a7e0ce-b53a-4bca-8f24-2e03b8153b35",
        "user_id": 1,
        "s3_key": "seed/resources/brian/gradient-descent-cheatsheet.md",
        "s3_bucket": "lantern-room",
        "filename": "gradient-descent-cheatsheet.md",
        "content_type": "text/markdown",
        "file_size": 271,
        "created_at": "2025-10-30 00:23:07.850994+00:00",
        "updated_at": "2025-10-30 00:23:07.850994+00:00"
      }
    },
    {
      "resource_id": "8d1b0a8a-9c02-4d32-9aa7-b47fe87cc1f4",
      "resource_type": "url",
      "source_url": "https://ml4all.example.com/notes/gradient-descent-intuition",
      "extracted_text": "Instructor-authored blog post describing gradient descent intuition with contour diagrams and annotated Python snippets for batch versus stochastic updates.",
      "metadata": {
        "source": "learner_share",
        "captured_at": "2024-02-12T14:05:00Z"
      }
    },
    {
      "resource_id": "2c54d82e-77aa-4fb1-9a6e-8213029ecf9c",
      "resource_type": "generated_source",
      "filename": "adaptive-learning-rates-supplement.txt",
      "extracted_text": "AI-generated supplement focusing on adaptive learning rate schedules, convergence guarantees, and comparing RMSProp with Adam for objectives not covered in learner notes.",
      "metadata": {
        "generated_at": "2024-02-15T09:40:00Z",
        "method": "ai_supplemental",
        "uncovered_lo_ids": [
          "grad_unit_lo_2"
        ]
      }
    }
  ],
  "art_image": null,
  "podcast_audio": {
    "id": "3b1f7e50-69e2-4e35-8f53-b2f2c126e90b",
    "user_id": 1,
    "s3_key": "seed/brian/audio/gradient-intro.mp3",
    "s3_bucket": "lantern-room",
    "filename": "gradient-intro.mp3",
    "content_type": "audio/mpeg",
    "file_size": 2621440,
    "duration_seconds": 95.0,
    "bitrate_kbps": 192,
    "sample_rate_hz": 44100,
    "transcript": "Welcome to Gradient Descent Mastery. This intro podcast previews the lessons and invites learners into the unit's narrative arc.",
    "created_at": "2025-10-30 00:23:07.850994+00:00",
    "updated_at": "2025-10-30 00:23:07.850994+00:00"
  },
  "learning_conversations": {
    "coach": [
      {
        "id": "f1e3b5d2-8a4e-4f2c-b1a3-c9d5e7f2a1b4",
        "user_key": "brian",
        "title": "Understanding learning rate selection",
        "status": "active",
        "metadata": {
          "topic": "Gradient Descent Fundamentals"
        },
        "resource_ids": [],
        "messages": [
          {
            "role": "user",
            "content": "I'm struggling with how to choose an appropriate learning rate. What's the relationship between learning rate and convergence?",
            "offset_seconds": 0
          },
          {
            "role": "assistant",
            "content": "Great question! The learning rate controls the step size in each update. A learning rate that's too high causes the algorithm to overshoot the minimum and diverge. Too low, and convergence becomes extremely slow. A good starting point is often 0.01 or 0.001, then adjust based on whether the loss is decreasing smoothly.",
            "offset_seconds": 10
          },
          {
            "role": "user",
            "content": "How can I tell if my learning rate is too high?",
            "offset_seconds": 15
          },
          {
            "role": "assistant",
            "content": "Watch your loss curve during training. If you see the loss jumping around wildly or increasing instead of decreasing, your learning rate is likely too high. You might also see NaN values appearing in your loss. In that case, reduce the learning rate by a factor of 10 and retry.",
            "offset_seconds": 20
          }
        ]
      }
    ],
    "assistant": [
      {
        "id": "a2c4d6e8-f0b2-4e6a-8c3d-b5f7e9a1c3d5",
        "user_key": "brian",
        "title": "Mini-batch vs batch gradient descent clarification",
        "status": "active",
        "metadata": {},
        "messages": [
          {
            "role": "user",
            "content": "What's the practical difference between batch and mini-batch gradient descent? When should I use each?",
            "offset_seconds": 0
          },
          {
            "role": "assistant",
            "content": "Batch gradient descent uses the entire dataset for each update, giving very stable gradient estimates but being slow. Mini-batch uses small subsets (typically 32-256 examples), balancing stability and speed. In practice, mini-batch is almost always better because it's faster and the noise actually helps escape local minima.",
            "offset_seconds": 5
          },
          {
            "role": "user",
            "content": "So I should always use mini-batch?",
            "offset_seconds": 10
          },
          {
            "role": "assistant",
            "content": "Essentially yes, for modern deep learning. Batch gradient descent is mostly historical. Stochastic (size=1) is too noisy for most cases. Mini-batch is the Goldilocks approach that works well for almost all problems.",
            "offset_seconds": 12
          },
          {
            "role": "user",
            "content": "What batch size do you recommend for starting?",
            "offset_seconds": 15
          },
          {
            "role": "assistant",
            "content": "Start with 32 or 64. These sizes are compatible with modern GPUs and provide a good balance. Adjust based on your GPU memory and dataset size. Larger batches can be more efficient but may generalize worse.",
            "offset_seconds": 17
          }
        ]
      }
    ]
  }
}