{
  "id": "9435f1bf-472d-47c5-a759-99beadd98077",
  "title": "Gradient Descent Mastery",
  "description": "A focused look at optimization fundamentals for machine learning practitioners.",
  "learner_level": "intermediate",
  "learning_objectives": [
    {
      "id": "grad_unit_lo_1",
      "title": "Explain Gradient Updates",
      "description": "Explain how gradient descent updates parameters",
      "bloom_level": "Understand"
    },
    {
      "id": "grad_unit_lo_2",
      "title": "Compare Descent Strategies",
      "description": "Compare batch, stochastic, and mini-batch strategies",
      "bloom_level": "Analyze"
    }
  ],
  "target_lesson_count": 2,
  "source_material": "Lecture notes on convex optimization, annotated Python notebooks, and practical training logs.",
  "generated_from_topic": true,
  "is_global": false,
  "owner_key": "brian",
  "art_image_description": "Weimar Edge illustration of Gradient Descent Mastery highlighting Explain Gradient Updates, Compare Descent Strategies with petrol blue geometry and gilt accents.",
  "podcast_transcript": "Welcome to Gradient Descent Mastery. This intro podcast previews the lessons and invites learners into the unit's narrative arc.",
  "podcast_voice": "Plain",
  "lessons": [
    {
      "id": "94e348bf-0a0e-4bd6-8d71-1112ced6326e",
      "title": "Gradient Descent Fundamentals",
      "learner_level": "intermediate",
      "source_material": "Walk-through of loss landscape intuition with quadratic examples and contour diagrams.",
      "objectives": [
        {
          "id": "grad_unit_lo_1",
          "title": "Explain Gradient Updates",
          "description": "Explain how gradient descent updates parameters",
          "bloom_level": "Understand"
        },
        {
          "id": "grad_unit_lo_1",
          "title": "Explain Gradient Updates",
          "description": "Explain how gradient descent updates parameters",
          "bloom_level": "Understand"
        }
      ],
      "glossary_terms": [
        {
          "term": "Learning Rate",
          "definition": "Scalar that scales the gradient step during optimization."
        },
        {
          "term": "Loss Landscape",
          "definition": "Surface describing how the loss changes with model parameters."
        },
        {
          "term": "Convergence",
          "definition": "Process of iteratively approaching an optimum."
        }
      ],
      "mini_lesson": "Gradient descent walks downhill on a loss landscape by following the negative gradient. Choosing the learning rate balances progress with stability. Too small and updates crawl; too large and the algorithm overshoots the valley. Visualizing contour plots helps practitioners tune the step size and anticipate oscillations.",
      "mcqs": [
        {
          "stem": "What happens when the learning rate is set too high?",
          "options": [
            {
              "text": "Updates overshoot and may diverge",
              "rationale_wrong": null
            },
            {
              "text": "Optimization halts immediately",
              "rationale_wrong": "Stopping occurs only if gradients become zero or errors occur."
            },
            {
              "text": "Gradients become zero regardless of the loss",
              "rationale_wrong": "Gradients depend on the loss surface, not the learning rate."
            }
          ],
          "correct_index": 0,
          "cognitive_level": "Analyze",
          "difficulty": "Medium",
          "misconceptions": [
            "higher_rate_faster"
          ],
          "correct_rationale": "Large steps can bounce across the valley and fail to converge."
        },
        {
          "stem": "Which equation represents one gradient descent step?",
          "options": [
            {
              "text": "θ := θ - α ∇J(θ)",
              "rationale_wrong": null
            },
            {
              "text": "θ := θ + α θ",
              "rationale_wrong": "This ignores the gradient information entirely."
            },
            {
              "text": "θ := θ / α",
              "rationale_wrong": "Dividing by the learning rate is unrelated to descent."
            }
          ],
          "correct_index": 0,
          "cognitive_level": "Remember",
          "difficulty": "Easy",
          "misconceptions": [
            "missing_gradient"
          ],
          "correct_rationale": "The gradient guides the step direction while α scales it."
        },
        {
          "stem": "Which quantity determines the direction of the update?",
          "options": [
            {
              "text": "The gradient of the loss",
              "rationale_wrong": null
            },
            {
              "text": "The learning rate alone",
              "rationale_wrong": "Learning rate only scales the update; it does not pick the direction."
            },
            {
              "text": "The batch size",
              "rationale_wrong": "Batch size influences noise, not direction."
            }
          ],
          "correct_index": 0,
          "cognitive_level": "Understand",
          "difficulty": "Medium",
          "misconceptions": [
            "direction_from_rate"
          ],
          "correct_rationale": "The gradient vector points toward steepest ascent, so we step opposite it."
        },
        {
          "stem": "When does vanilla gradient descent typically stop iterating?",
          "options": [
            {
              "text": "When the gradient norm falls near zero",
              "rationale_wrong": null
            },
            {
              "text": "After a single update",
              "rationale_wrong": "Multiple updates are required to reach an optimum."
            },
            {
              "text": "Once the loss increases once",
              "rationale_wrong": "A temporary increase can occur without ending training."
            }
          ],
          "correct_index": 0,
          "cognitive_level": "Analyze",
          "difficulty": "Medium",
          "misconceptions": [
            "stop_on_first_increase"
          ],
          "correct_rationale": "Convergence is reached when gradients vanish or a tolerance threshold is met."
        },
        {
          "stem": "Which hyperparameter scales how far each step travels?",
          "options": [
            {
              "text": "Learning rate",
              "rationale_wrong": null
            },
            {
              "text": "Momentum",
              "rationale_wrong": "Momentum adds history but does not alone scale basic step size."
            },
            {
              "text": "Epoch count",
              "rationale_wrong": "Epochs count passes through data, not step length."
            }
          ],
          "correct_index": 0,
          "cognitive_level": "Remember",
          "difficulty": "Easy",
          "misconceptions": [
            "epoch_controls_step"
          ],
          "correct_rationale": "The learning rate multiplies the gradient to set step magnitude."
        }
      ],
      "misconceptions": [],
      "confusables": [],
      "short_answers": [
        {
          "stem": "Which vector do we move opposite to descend the loss?",
          "canonical_answer": "negative gradient",
          "acceptable_answers": [
            "-gradient"
          ],
          "wrong_answers": [
            {
              "answer": "learning rate",
              "explanation": "The learning rate only scales the update; it is not the direction.",
              "misconception_ids": [
                "direction_from_rate"
              ]
            },
            {
              "answer": "loss surface",
              "explanation": "The surface defines the landscape but not the direction of travel.",
              "misconception_ids": []
            }
          ],
          "explanation_correct": "Gradient descent steps against the gradient vector to decrease the loss.",
          "learning_objectives_covered": [
            "grad_unit_lo_1"
          ],
          "cognitive_level": "Apply"
        },
        {
          "stem": "What term describes the function we minimize during training?",
          "canonical_answer": "loss function",
          "acceptable_answers": [
            "cost function",
            "objective"
          ],
          "wrong_answers": [
            {
              "answer": "activation",
              "explanation": "Activations are neuron outputs, not the optimization target.",
              "misconception_ids": []
            },
            {
              "answer": "dataset",
              "explanation": "The dataset is the input, while the loss function measures error.",
              "misconception_ids": []
            }
          ],
          "explanation_correct": "Training minimizes a loss function that measures prediction error.",
          "learning_objectives_covered": [
            "grad_unit_lo_1"
          ],
          "cognitive_level": "Remember"
        },
        {
          "stem": "Which hyperparameter controls the step size per update?",
          "canonical_answer": "learning rate",
          "acceptable_answers": [
            "step size"
          ],
          "wrong_answers": [
            {
              "answer": "batch size",
              "explanation": "Batch size affects noise, not the scaling of each gradient step.",
              "misconception_ids": [
                "bigger_always_better"
              ]
            },
            {
              "answer": "momentum",
              "explanation": "Momentum accumulates velocity but does not replace the rate itself.",
              "misconception_ids": []
            }
          ],
          "explanation_correct": "The learning rate multiplies the gradient to set how far we move.",
          "learning_objectives_covered": [
            "grad_unit_lo_1"
          ],
          "cognitive_level": "Understand"
        },
        {
          "stem": "What do we call a point where the gradient becomes zero?",
          "canonical_answer": "stationary point",
          "acceptable_answers": [
            "critical point"
          ],
          "wrong_answers": [
            {
              "answer": "global maximum",
              "explanation": "A zero gradient could be minimum, maximum, or saddle point.",
              "misconception_ids": []
            },
            {
              "answer": "divergence",
              "explanation": "Divergence means the algorithm blew up, not that gradients vanished.",
              "misconception_ids": []
            }
          ],
          "explanation_correct": "Stationary points have zero gradient and mark potential optima.",
          "learning_objectives_covered": [
            "grad_unit_lo_1"
          ],
          "cognitive_level": "Analyze"
        },
        {
          "stem": "Which variant uses the entire dataset for each update?",
          "canonical_answer": "batch gradient descent",
          "acceptable_answers": [
            "full batch"
          ],
          "wrong_answers": [
            {
              "answer": "stochastic descent",
              "explanation": "Stochastic descent uses one example per update.",
              "misconception_ids": []
            },
            {
              "answer": "mini-batch",
              "explanation": "Mini-batch uses subsets, not the complete dataset.",
              "misconception_ids": [
                "mini_batch_is_exact"
              ]
            }
          ],
          "explanation_correct": "Batch gradient descent computes gradients over all examples before stepping.",
          "learning_objectives_covered": [
            "grad_unit_lo_1"
          ],
          "cognitive_level": "Understand"
        }
      ]
    },
    {
      "id": "c91e9256-26f8-45aa-8390-3f80a903824f",
      "title": "Mini-Batch Strategies",
      "learner_level": "intermediate",
      "source_material": "Case study comparing batch, stochastic, and mini-batch training on image classifiers.",
      "objectives": [
        {
          "id": "grad_unit_lo_2",
          "title": "Compare Descent Strategies",
          "description": "Compare batch, stochastic, and mini-batch strategies",
          "bloom_level": "Analyze"
        },
        {
          "id": "grad_unit_lo_2",
          "title": "Compare Descent Strategies",
          "description": "Compare batch, stochastic, and mini-batch strategies",
          "bloom_level": "Analyze"
        }
      ],
      "glossary_terms": [
        {
          "term": "Batch Gradient Descent",
          "definition": "Optimization that uses the full dataset each update."
        },
        {
          "term": "Stochastic Gradient Descent",
          "definition": "Optimization using one example per update."
        },
        {
          "term": "Mini-Batch",
          "definition": "Subset of examples used per update to balance variance and efficiency."
        }
      ],
      "mini_lesson": "Mini-batches blend the stability of batch training with the responsiveness of stochastic updates. Smaller batches introduce gradient noise that can escape shallow minima, while larger batches leverage hardware parallelism. Practitioners often start with powers of two (32, 64, 128) and adjust based on validation loss curves.",
      "mcqs": [
        {
          "stem": "Why choose mini-batch gradient descent over pure stochastic descent?",
          "options": [
            {
              "text": "It smooths gradient noise while remaining efficient",
              "rationale_wrong": null
            },
            {
              "text": "It eliminates the need for a learning rate",
              "rationale_wrong": "Learning rate tuning is still required."
            },
            {
              "text": "It guarantees convergence in one epoch",
              "rationale_wrong": "Convergence still depends on many factors."
            }
          ],
          "correct_index": 0,
          "cognitive_level": "Analyze",
          "difficulty": "Medium",
          "misconceptions": [
            "mini_batch_is_exact"
          ],
          "correct_rationale": "Mini-batches reduce variance while keeping computation tractable."
        },
        {
          "stem": "Which batch size balances speed and noise for many image tasks?",
          "options": [
            {
              "text": "A power of two such as 64",
              "rationale_wrong": null
            },
            {
              "text": "Batch size of 1 to avoid memory use",
              "rationale_wrong": "Size 1 is pure stochastic descent."
            },
            {
              "text": "Full dataset size each step",
              "rationale_wrong": "Full batches maximize stability but reduce responsiveness."
            }
          ],
          "correct_index": 0,
          "cognitive_level": "Apply",
          "difficulty": "Easy",
          "misconceptions": [
            "bigger_always_better"
          ],
          "correct_rationale": "Powers of two align with hardware and offer a practical trade-off."
        },
        {
          "stem": "How does decreasing batch size affect gradient estimates?",
          "options": [
            {
              "text": "Noise increases, enabling exploratory moves",
              "rationale_wrong": null
            },
            {
              "text": "Noise decreases to zero",
              "rationale_wrong": "Noise only vanishes with full-batch updates."
            },
            {
              "text": "Gradients become biased upward",
              "rationale_wrong": "Mini-batch gradients remain unbiased on average."
            }
          ],
          "correct_index": 0,
          "cognitive_level": "Understand",
          "difficulty": "Medium",
          "misconceptions": [
            "variance_equals_bias"
          ],
          "correct_rationale": "Smaller batches sample fewer examples so variance grows, which can help escape shallow minima."
        },
        {
          "stem": "Which tool accelerates mini-batch training on GPUs?",
          "options": [
            {
              "text": "Vectorized tensor operations",
              "rationale_wrong": null
            },
            {
              "text": "Serial parameter updates",
              "rationale_wrong": "Serial updates negate parallel benefits."
            },
            {
              "text": "Manual gradient calculation",
              "rationale_wrong": "Automatic differentiation handles gradients efficiently."
            }
          ],
          "correct_index": 0,
          "cognitive_level": "Apply",
          "difficulty": "Medium",
          "misconceptions": [
            "gpu_needs_serial"
          ],
          "correct_rationale": "Leveraging tensor libraries keeps mini-batch operations parallel and fast."
        },
        {
          "stem": "What schedule often follows a plateau in validation loss?",
          "options": [
            {
              "text": "Reduce the learning rate",
              "rationale_wrong": null
            },
            {
              "text": "Increase batch size immediately",
              "rationale_wrong": "Larger batches may hide useful noise instead of improving convergence."
            },
            {
              "text": "Restart training from scratch",
              "rationale_wrong": "Restarts waste progress unless using cyclic schedules."
            }
          ],
          "correct_index": 0,
          "cognitive_level": "Analyze",
          "difficulty": "Medium",
          "misconceptions": [
            "always_increase_batch"
          ],
          "correct_rationale": "Reducing the learning rate after a plateau helps mini-batch updates settle into minima."
        }
      ],
      "misconceptions": [],
      "confusables": [],
      "short_answers": [
        {
          "stem": "What noise-reducing technique averages gradients across replicas?",
          "canonical_answer": "gradient accumulation",
          "acceptable_answers": [
            "gradient averaging"
          ],
          "wrong_answers": [
            {
              "answer": "dropout",
              "explanation": "Dropout regularizes activations but does not average gradients.",
              "misconception_ids": []
            },
            {
              "answer": "weight decay",
              "explanation": "Weight decay adds a penalty term instead of averaging gradients.",
              "misconception_ids": []
            }
          ],
          "explanation_correct": "Accumulating gradients over micro-batches keeps updates stable when memory is limited.",
          "learning_objectives_covered": [
            "grad_unit_lo_2"
          ],
          "cognitive_level": "Apply"
        },
        {
          "stem": "Which schedule gradually lowers the learning rate during training?",
          "canonical_answer": "learning rate decay",
          "acceptable_answers": [
            "lr decay",
            "annealing"
          ],
          "wrong_answers": [
            {
              "answer": "batch norm",
              "explanation": "Batch normalization rescales activations, not the learning rate.",
              "misconception_ids": []
            },
            {
              "answer": "weight initialization",
              "explanation": "Initialization occurs before training and is not a schedule.",
              "misconception_ids": []
            }
          ],
          "explanation_correct": "Learning rate decay reduces step sizes so mini-batches converge smoothly.",
          "learning_objectives_covered": [
            "grad_unit_lo_2"
          ],
          "cognitive_level": "Understand"
        },
        {
          "stem": "What metric do practitioners watch to detect overfitting?",
          "canonical_answer": "validation loss",
          "acceptable_answers": [
            "val loss",
            "validation error"
          ],
          "wrong_answers": [
            {
              "answer": "training accuracy",
              "explanation": "Training accuracy rises even when generalization suffers.",
              "misconception_ids": []
            },
            {
              "answer": "gradient norm",
              "explanation": "Gradient norms show optimization progress, not overfitting directly.",
              "misconception_ids": []
            }
          ],
          "explanation_correct": "Validation loss reveals whether mini-batch updates still improve generalization.",
          "learning_objectives_covered": [
            "grad_unit_lo_2"
          ],
          "cognitive_level": "Analyze"
        },
        {
          "stem": "Which optimizer adds momentum to damp oscillations?",
          "canonical_answer": "momentum",
          "acceptable_answers": [
            "sgd with momentum"
          ],
          "wrong_answers": [
            {
              "answer": "adam",
              "explanation": "Adam adapts per-parameter rates beyond simple momentum.",
              "misconception_ids": []
            },
            {
              "answer": "dropout",
              "explanation": "Dropout randomly masks activations; it is not an optimizer.",
              "misconception_ids": []
            }
          ],
          "explanation_correct": "Momentum smooths noisy mini-batch gradients by accumulating velocity.",
          "learning_objectives_covered": [
            "grad_unit_lo_2"
          ],
          "cognitive_level": "Apply"
        },
        {
          "stem": "How do we describe running several batches in parallel on multiple GPUs?",
          "canonical_answer": "data parallelism",
          "acceptable_answers": [
            "data parallel"
          ],
          "wrong_answers": [
            {
              "answer": "model parallelism",
              "explanation": "Model parallelism splits layers across devices instead of batches.",
              "misconception_ids": []
            },
            {
              "answer": "quantization",
              "explanation": "Quantization compresses weights rather than distributing batches.",
              "misconception_ids": []
            }
          ],
          "explanation_correct": "Data parallelism copies the model on each device and splits mini-batches for speed.",
          "learning_objectives_covered": [
            "grad_unit_lo_2"
          ],
          "cognitive_level": "Understand"
        }
      ]
    }
  ],
  "resources": [
    {
      "id": "bc9ea4cb-ac1d-4712-aeb3-a6a880cc9f38",
      "user_id": 1,
      "resource_type": "file_upload",
      "filename": "gradient-descent-cheatsheet.md",
      "extracted_text": "Gradient descent tuning cheatsheet\n• Start with learning rate 0.1 for convex demos, decay by 0.5 when oscillations persist.\n• Clip gradients above 5.0 to stabilize mini-batch updates.\n• Log validation loss every 10 steps; trigger warm restart if plateau > 30 steps.",
      "extraction_metadata": {},
      "file_size": 271,
      "object_store_document_id": "51a7e0ce-b53a-4bca-8f24-2e03b8153b35",
      "created_at": "2025-10-30 00:23:07.850994+00:00",
      "updated_at": "2025-10-30 00:23:07.850994+00:00",
      "document": {
        "id": "51a7e0ce-b53a-4bca-8f24-2e03b8153b35",
        "user_id": 1,
        "s3_key": "seed/resources/brian/gradient-descent-cheatsheet.md",
        "s3_bucket": "lantern-room",
        "filename": "gradient-descent-cheatsheet.md",
        "content_type": "text/markdown",
        "file_size": 271,
        "created_at": "2025-10-30 00:23:07.850994+00:00",
        "updated_at": "2025-10-30 00:23:07.850994+00:00"
      }
    },
    {
      "resource_id": "8d1b0a8a-9c02-4d32-9aa7-b47fe87cc1f4",
      "resource_type": "url",
      "source_url": "https://ml4all.example.com/notes/gradient-descent-intuition",
      "extracted_text": "Instructor-authored blog post describing gradient descent intuition with contour diagrams and annotated Python snippets for batch versus stochastic updates.",
      "metadata": {
        "source": "learner_share",
        "captured_at": "2024-02-12T14:05:00Z"
      }
    },
    {
      "resource_id": "2c54d82e-77aa-4fb1-9a6e-8213029ecf9c",
      "resource_type": "generated_source",
      "filename": "adaptive-learning-rates-supplement.txt",
      "extracted_text": "AI-generated supplement focusing on adaptive learning rate schedules, convergence guarantees, and comparing RMSProp with Adam for objectives not covered in learner notes.",
      "metadata": {
        "generated_at": "2024-02-15T09:40:00Z",
        "method": "ai_supplemental",
        "uncovered_lo_ids": [
          "grad_unit_lo_2"
        ]
      }
    }
  ],
  "art_image": null,
  "podcast_audio": {
    "id": "3b1f7e50-69e2-4e35-8f53-b2f2c126e90b",
    "user_id": 1,
    "s3_key": "seed/brian/audio/gradient-intro.mp3",
    "s3_bucket": "lantern-room",
    "filename": "gradient-intro.mp3",
    "content_type": "audio/mpeg",
    "file_size": 2621440,
    "duration_seconds": 95.0,
    "bitrate_kbps": 192,
    "sample_rate_hz": 44100,
    "transcript": "Welcome to Gradient Descent Mastery. This intro podcast previews the lessons and invites learners into the unit's narrative arc.",
    "created_at": "2025-10-30 00:23:07.850994+00:00",
    "updated_at": "2025-10-30 00:23:07.850994+00:00"
  }
}
